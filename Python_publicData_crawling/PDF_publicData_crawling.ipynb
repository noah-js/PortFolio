{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "import tabula\n",
    "from tabula import wrapper\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import wget\n",
    "\n",
    "##데이터 crawling Url 생성 함수\n",
    "def makeURL(myUrl, myKey, myParameter):\n",
    "    # myUrl = \"http://192.168.1.120/index.php?\"\n",
    "    url = myUrl + myKey + \"&\" + myParameter\n",
    "\n",
    "    url = url.rstrip('&')\n",
    "    return url\n",
    "\n",
    "##xml형석 검사 함수\n",
    "def xmlProcess(url):\n",
    "    response = requests.get(url)\n",
    "    # Check if page is up\n",
    "    if response.status_code == 200:\n",
    "        # Convert webpage to %Data\n",
    "        Data = BeautifulSoup(response.text, 'lxml-xml')\n",
    "        result = []\n",
    "        rows = 0\n",
    "        columnName = []\n",
    "        # search Item all item tag\n",
    "        iterData = Data.find_all('item')\n",
    "        for item in iterData:\n",
    "            item_list = []\n",
    "            # Fill the value in one row\n",
    "            for tag in item.find_all():\n",
    "                try:\n",
    "                    tagname = tag.name\n",
    "                    if rows == 0:\n",
    "                        columnName.append(tagname)\n",
    "                    item_list.append(item.find(tagname).text)\n",
    "                except Exception as e:\n",
    "                    print(\"This row will be ignored. \", item_list)\n",
    "            rows = rows + 1\n",
    "            result.append(item_list)\n",
    "    finalResult = pd.DataFrame(result)\n",
    "    finalResult.columns = columnName\n",
    "    print(finalResult)\n",
    "    return finalResult\n",
    "\n",
    "##Json형식 검사함수\n",
    "def jsonProcess(url):\n",
    "\n",
    "    # 정상 여부 확인 (200 정상)\n",
    "    response = requests.get(url)\n",
    "    # JSON 데이터 획득\n",
    "    json = response.json()\n",
    "    # PandasDataframe변환\n",
    "    df = json_normalize(json)\n",
    "    return df\n",
    "\n",
    "##csv형식 검사함수\n",
    "def csvProcess(url):\n",
    "    # 정상 여부 확인 (200 정상)\n",
    "    response = requests.get(url)\n",
    "    df = pd.read_csv(url, encoding=\"ms949\")\n",
    "    return df\n",
    "\n",
    "##pdf파일을 받아 저장까지 완료하는 함수\n",
    "def pdfProcess(inputFolder,url):\n",
    "    resp = requests.get(\"http://fsc.go.kr/info/trd_list.jsp?menu=7230000&bbsid=BBS0069\")\n",
    "    resp.encoding='utf-8'\n",
    "    html = resp.text\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #프로그램 실행시마다 최신데이터를 데이터를 가져오도록 하는 코드 \n",
    "    #데이터 추출하기\n",
    "    originalData  = bs.select(\"#contents > div.board > table > tbody > tr > td > a\")\n",
    "\n",
    "    #pdf문서\n",
    "    convertedData = str(originalData[2])\n",
    "\n",
    "    dailyUpdated = convertedData.split('\"')[1].split('amp;')[1]\n",
    "#     url = \"http://fsc.go.kr/downManager?bbsid=BBS0069&\"\n",
    "    url = url + \"&\"+ dailyUpdated\n",
    "    df2 = wrapper.read_pdf(url,\n",
    "              multiple_tables=True,\n",
    "              pages=\"all\",pandas_options={\"header\":0})\n",
    "\n",
    "    #csv 파일로 저장하기 \n",
    "    #파일이름에 반영할 현재 날짜 구하기 \n",
    "    currentYear = datetime.today().year\n",
    "    currentMonth = datetime.today().month\n",
    "    currentDate = datetime.today().day\n",
    "\n",
    "    currentYear\n",
    "\n",
    "    currentYear = str(currentYear)[-2:]\n",
    "    if (currentMonth < 10):\n",
    "        currentMonth = \"0\" + str(currentMonth)\n",
    "    else:\n",
    "        currentMonth = str(currentMonth)\n",
    "\n",
    "    if (currentDate < 10):\n",
    "        currentDate = \"0\" + str(currentDate)\n",
    "    else:\n",
    "        currentDate = str(currentDate)\n",
    "\n",
    "    today = currentYear + currentMonth + currentDate\n",
    "\n",
    "    #################################저장 수정필요\n",
    "    for i in range(len(df2)):\n",
    "        fileName = inputFolder + \"_\" + today + \"_\" + str(i)\n",
    "        fullOutPath = outPath+inputFolder+\"/\"+inputFolder+inputFile+str(i)+\".csv\"\n",
    "    #         df2[i].to_sql(fileName, engine, if_exists='replace', index=False)\n",
    "        df2[i].to_csv(fullOutPath, encoding = \"ms949\", index = False)\n",
    "\n",
    "##데이터 폴더 생성 함수\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "##구글 스프레드 시트 활용\n",
    "dataList = pd.read_csv(\"\") ## googleSheet link연결 서비스키 보안\n",
    "print(\"### The total number of target data is \" + str(len(dataList)))\n",
    "\n",
    "dataList = dataList[dataList['사이트'].notnull() ]\n",
    "print(dataList[[\"사이트\"]])\n",
    "print(\"### The total number of filtered data is \" + str(len(dataList)))\n",
    "\n",
    "dataList = dataList[   dataList['폴더명'] == \"342_금융시장동향\" ]\n",
    "dataList\n",
    "\n",
    "outPath = \"./outbound/\"\n",
    "folderList = dataList[\"폴더명\"].tolist()\n",
    "\n",
    "for i in folderList:\n",
    "    createFolder(outPath+i)\n",
    "\n",
    "dataList = dataList.fillna(\"\")\n",
    "dataList = dataList.reset_index(drop=True)\n",
    "\n",
    "for dataCount in range(0,len(dataList)):\n",
    "    inputUrl = dataList.loc[dataCount, \"사이트\"]\n",
    "    inputKey = dataList.loc[dataCount, \"서비스키\"]\n",
    "    inputParameter = dataList.loc[dataCount, \"파라미터\"]\n",
    "    inputFolder = dataList.loc[dataCount, \"폴더명\"]\n",
    "    inputFile = dataList.loc[dataCount, \"서비스명\"]\n",
    "    inputDataType = dataList.loc[dataCount, \"데이터타입\"]\n",
    "    inputRefUrl = dataList.loc[dataCount, \"참고문서\"]\n",
    "    inputRefType = dataList.loc[dataCount, \"참고문서타입\"]\n",
    "    print(inputUrl)\n",
    "\n",
    "    url = makeURL(inputUrl,inputKey,inputParameter)\n",
    "\n",
    "    print(\"fullUrl is \" + url)\n",
    "\n",
    "    newDF = pd.DataFrame()\n",
    "    try:\n",
    "        if (inputDataType == \"xml\"):\n",
    "            try:\n",
    "                newDF = cf.xmlProcess(url)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        elif(inputDataType == \"json\"):\n",
    "            newDF = jsonProcess(url)\n",
    "        elif(inputDataType == \"csv\"):\n",
    "            newDF = csvProcess(url)\n",
    "        elif(inputDataType == \"pdf\"):\n",
    "            newDF = pdfProcess(inputFolder, url)\n",
    "        print(\"저장 되었습니다\")\n",
    "    except Exception as a:\n",
    "        print(a)\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
